---
title: "Building Social Companions"
excerpt: "<img width='400px' src='/images/Educational-Robots.png'> <br><br> This line of work contributes to our understanding of how robotic products and services might function in real-world environments is my group’s work on long-term interaction with robotic social companions."
collection: portfolio
author_profile: false
---

<img width='600px' src='/images/Educational-Robots.png'>

## Overview

This line of work contributes to our understanding of how robotic products and services might function in real-world environments is my group’s work on **long-term interaction** with robotic social companions, focusing on family-robot interaction, conversational privacy, and ways of maintaining interaction over long periods (months).

Over the course of the last four years, we have iteratively designed a learning companion robot for middle schoolers, called Minnie, that aimed to socially augment the otherwise solitary activity of reading. Children read to Minnie, and the robot occasionally comments on the story, reflecting on characters and events and connecting the story to other stories they have read. The robot also helps the child choose books to read based on the child’s interests and meet reading goals. We have fabricated multiple copies of Minnie and carried out in-home evaluation studies, including a 14-day deployment study, which revealed that children established an emotional bond with the robot over the course of the 14 days and reported being more motivated to read and better understanding the content with the robot than with a paper-based reading activity. We also have conducted laboratory evaluations of how Minnie can help build interested in science reading, and we are now planning a summer-long deployment of Minnie with low-interest readers to better understand how interactions with and perceptions of the robot changes over a longer period.

Here is a short talk I gave at the 2022 Furhat Conference on this topic:

<iframe width="560" height="315" src="https://www.youtube.com/embed/fmu4aNhYdK8" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>

## Research Team

In this work, I collaborate with [Joseph Michaelis](https://lsri.uic.edu/profiles/michaelis-joseph/), [David Shaffer](https://lsri.uic.edu/profiles/michaelis-joseph/), and [Sarah Sebo](https://sarahsebo.com).

The students who participate in this work include [Bengisu Cagiltay](https://www.linkedin.com/in/bengisucagiltay/) and [Nathan White](https://robotics.wisc.edu/staff/henrichs-curt/).

## Publications & Videos

The key publications that has resulted from this work include:

* Preliminary field study — [CHI 2017 Paper](https://jmich.people.uic.edu/pubs/chi17-michaelis.pdf), [Talk](https://youtu.be/12htE6jwxto)
* Two-week deployment — [Science Robotics Paper](https://robotics.sciencemag.org/content/3/21/eaat5999.full.pdf)
* Lab study — [IDC 2019 Paper](https://jmich.people.uic.edu/pubs/Michaelis%20&%20Mutlu%20-%20IDC%202019.pdf) — **IDC 2019 Honorable Mention**
* Participatory design with families — [IDC 2019 Paper](https://jmich.people.uic.edu/pubs/Michaelis%20&%20Mutlu%20-%20IDC%202019.pdf), [Talk](https://youtu.be/P2nFoD60hcA)
* Unboxing — [CHI 2022 Paper](https://dl.acm.org/doi/pdf/10.1145/3491102.3501955), [Video](https://www.youtube.com/watch?v=cqwmvs6nkog), [Talk](https://www.youtube.com/watch?v=1LMYwqfzD84) — **CHI 2022 Honorable Mention**
* Confidant — a privacy controller for social robot – [HRI 2023 Paper](https://peopleandrobots.wisc.edu/wp-content/uploads/sites/1469/2022/02/2201.02712.pdf), [Talk](https://www.youtube.com/watch?v=sWTOmRP2Jf0)
* Caretaking [IDC 2022 Paper](https://arxiv.org/pdf/2205.09055) — **IDC 2022 Best Short paper**
* Four-week deployment — [HRI 2023 Paper](https://www.researchgate.net/profile/Bengisu-Cagiltay/publication/368357286_Off_Script_Design_Opportunities_Emerging_from_Long-Term_Social_Robot_Interactions_In-the-Wild/links/6462da3efbaf5b27a4cb5611/Off-Script-Design-Opportunities-Emerging-from-Long-Term-Social-Robot-Interactions-In-the-Wild.pdf), [Talk (download)](https://dl.acm.org/action/downloadSupplement?doi=10.1145%2F3568162.3576978&file=HRI23-fp1125.mp4)

This work has also appeared in popular scientific news outlets, including:

* **Popular Science:** [Kids aren’t reading enough. One solution? robots.](https://www.popsci.com/reading-robot/)
* **Discover:** [Want Your Kids to Read More? Get ‘Em a Robot](http://Want%20Your%20Kids%20to%20Read%20More?%20Get%20'Em%20a%20Robot)
* **Inverse:** [With a Robot by Their Side, Kids Understand More of What They’re Reading](https://www.inverse.com/article/48249-children-are-more-motivated-to-read-when-they-ve-got-a-robot-by-their-side)

<table>
    <tr>
        <td class="style24" style="width: 400px">
            <div id='outerdiv' style="width:400px; overflow-x:hidden;">
                <iframe src="https://www.youtube.com/embed/cqwmvs6nkog" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
            </div>
        </td>
        <td class="style24" style="width: 400px">
            <div id='outerdiv' style="width:400px; overflow-x:hidden;">
                <iframe src="https://www.youtube.com/embed/P2nFoD60hcA" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
            </div>
        </td>
    </tr>
        <tr>
        <td class="style24" style="width: 400px">
            <div id='outerdiv' style="width:400px; overflow-x:hidden;">
                <iframe src="https://www.youtube.com/embed/12htE6jwxto" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
            </div>
        </td>
        <td class="style24" style="width: 400px">
            <div id='outerdiv' style="width:400px; overflow-x:hidden;">
                <iframe src="https://www.youtube.com/embed/sWTOmRP2Jf0" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
            </div>
        </td>
    </tr>
       <tr>
           <td class="style24" style="width: 400px">
            <div id='outerdiv' style="width:400px; overflow-x:hidden;">
                <iframe src="https://www.youtube.com/embed/pccow6lkc88" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
            </div>
         </td>
          <td class="style24" style="width: 400px">
            <div id='outerdiv' style="width:400px; overflow-x:hidden;">
                <iframe src="https://www.youtube.com/embed/rN8K11LgfgY" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
            </div>
         </td>
    </tr>
</table>

## Funding

This work is supported by NSF awards [1906854](https://www.nsf.gov/awardsearch/showAward?AWD_ID=1906854&HistoricalAwards=false), [1822872](https://www.nsf.gov/awardsearch/showAward?AWD_ID=1822872), and [2247381](https://www.nsf.gov/awardsearch/showAward?AWD_ID=2247381&HistoricalAwards=false).

![NSF Logo](\images\NSF.png)
