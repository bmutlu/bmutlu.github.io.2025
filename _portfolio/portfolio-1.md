---
title: "HRI Design Tools"
excerpt: "<img width='400px' src='/images/Programming.png'> <br><br> This thread of research builds a suite of tools we have been building to support the unique and complex task of designing robotics applications for human use in collaboration with researchers in programming languages."
collection: portfolio
author_profile: false
---

<img width='600px' src='/images/Programming.png'>

## Overview

Our explorations of the design space for robotic technologies have demonstrated that the interactions afforded by these technologies—such as the robotic arm handing objects over at precisely the right time—can be very powerful but highly complex. Creating such interactions will require designers to perform design tasks that are substantially more complex and will demand methods and tools that empower them in tackling such complexity. In a second thread of research, my group has drawn on formal methods, specifically program analysis and synthesis, to reimagine the design process for robotic technologies as a mixed-initiative interaction where prototyping, simulation, and implementation tasks are performed by the computer and designers can focus on the creative and collaborative aspects of the design process.

In this thread of research, I build a suite of tools we have been building to support the unique and complex task of designing robotics applications for human use in collaboration with researchers in programming languages. My collaborators in this line of work include [Aws Albarghouthi](http://pages.cs.wisc.edu/~aws/), [Allison Sauppé](https://cs.uwlax.edu/~asauppe/), [Maya Cakmak](https://homes.cs.washington.edu/~mcakmak/), and [Rastislav Bodik](https://homes.cs.washington.edu/~bodik/). Students who are participating in this work include [David Porfirio](http://pages.cs.wisc.edu/~dporfirio/) (now at NRL), [Laura Stegner](http://laurastegner.com/), and [Andrew Schoen](https://andrewjschoen.github.io/).

## Tools

Some of the tools we have built in this thread of research include:

* [RoVer](https://par.nsf.gov/servlets/purl/10080246) — a visual authoring environment that verifies robot programs for social norms and task completeness — [Paper](https://par.nsf.gov/servlets/purl/10080246), [Talk](https://www.youtube.com/watch?v=hXZwBicPR_E) — [*UIST 2018 Best Paper Award*](https://uist.acm.org/uist2018/)

* [Synthé](http://pages.cs.wisc.edu/~aws/papers/uist19.pdf) — an authoring system that enables designers to demonstrate social interactions through role play — [Paper](http://pages.cs.wisc.edu/~aws/papers/uist19.pdf), [Talk](https://www.youtube.com/watch?v=bxrN6dW5lH8)

* [Figaro](https://dl.acm.org/doi/abs/10.1145/3411764.3446864) — a tangible authoring system to situate human-robot interactions in projected plans of environments — [Paper](https://dl.acm.org/doi/abs/10.1145/3411764.3446864), [Talk](https://www.youtube.com/watch?v=7ox53gOHx4I)

* [Authr](https://peopleandrobots.wisc.edu/wp-content/uploads/sites/1469/2020/12/Authr__A_Task_Authoring_Environment_for_Human_Robot_Teams__UIST_2020__Camera_Ready_Accessible.pdf) — a visual task authoring environment to translate human work plans into human-robot team workplans — [Paper](https://peopleandrobots.wisc.edu/wp-content/uploads/sites/1469/2020/12/Authr__A_Task_Authoring_Environment_for_Human_Robot_Teams__UIST_2020__Camera_Ready_Accessible.pdf), [Short Talk](https://www.youtube.com/watch?v=mmdvRNBR7mc), [Full Talk](https://www.youtube.com/watch?v=ZeVrv2l92pM)

* [Tabula](https://pages.cs.wisc.edu/~aws/papers/hri23.pdf) — a multimodal task authoring environment that integrates speech and gesture input and program repair to construct programs from partial input — [Paper](https://pages.cs.wisc.edu/~aws/papers/hri23.pdf), [Talk (listed under Supplemental Material)](https://dl.acm.org/doi/abs/10.1145/3568162.3576991)

* [CoFrame](https://peopleandrobots.wisc.edu/wp-content/uploads/sites/1469/2022/04/3523760.3523788.pdf) — an environment for programming collaborative robots and for training in robot programming, built on a model of expertise in robotics — [Paper]([url](https://peopleandrobots.wisc.edu/wp-content/uploads/sites/1469/2022/04/3523760.3523788.pdf)), [Talk]([url](https://www.youtube.com/watch?v=f8dM1gbyTGw))

* [Lively](https://andrewjschoen.github.io/assets/files/HRI_2023_Schoen_Sullivan_Lively.pdf) — a programming environment to generate configurable, real-time, task-based and communicative or socially-expressive motion for collaborative and social robotics — [Paper](https://andrewjschoen.github.io/assets/files/HRI_2023_Schoen_Sullivan_Lively.pdf), [Talk (download)](https://dl.acm.org/action/downloadSupplement?doi=10.1145%2F3568162.3576982&file=HRI23-fp1285.mp4), [Short Video (download)](https://dl.acm.org/action/downloadSupplement?doi=10.1145%2F3568162.3576982&file=hrifp1285.mp4) — [*HRI 2023 Best Systems Paper Award*](https://humanrobotinteraction.org/2023/awards/)

## Videos

<style>
table, td, th, tr {
   border: none;
}
thead {
   background-color: rgba(0, 0, 0, 0.0);
   border-bottom: 0px;
}
tr.border-bottom {
   border-bottom: 0px;
}
</style>

<table>
    <tr>
        <td class="style24" style="width: 400px">
            <div id='outerdiv' style="width:400px; overflow-x:hidden;">
                <iframe src="https://www.youtube.com/embed/3Kj5mJ0GmLk" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
            </div>
        </td>
        <td class="style24" style="width: 400px">
            <div id='outerdiv' style="width:400px; overflow-x:hidden;">
                <iframe src="https://www.youtube.com/embed/4mml_6Dw7kU" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
            </div>
        </td>
    </tr>
        <tr>
        <td class="style24" style="width: 400px">
            <div id='outerdiv' style="width:400px; overflow-x:hidden;">
                <iframe src="https://www.youtube.com/embed/bQP1GYbda5I" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
            </div>
        </td>
        <td class="style24" style="width: 400px">
            <div id='outerdiv' style="width:400px; overflow-x:hidden;">
                <iframe src="https://www.youtube.com/embed/Dbjtg6N4cjY" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
            </div>
        </td>
    </tr>
       <tr>
           <td class="style24" style="width: 400px">
            <div id='outerdiv' style="width:400px; overflow-x:hidden;">
                <iframe src="https://www.youtube.com/embed/sekox5SlDfI" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
            </div>
         </td>
          <td class="style24" style="width: 400px">
            <div id='outerdiv' style="width:400px; overflow-x:hidden;">
                <iframe src="https://www.youtube.com/embed/fBk2MhQ6reY" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
            </div>
         </td>
    </tr>
</table>

This project is supported by NSF awards [1651129](https://www.nsf.gov/awardsearch/showAward?AWD_ID=1651129) and [1925043](https://www.nsf.gov/awardsearch/showAward?AWD_ID=1925043&HistoricalAwards=false).

![NSF logo](\images\NSF.png)
